{'state_count': 5, 'action_count': 2}
COMPUTING REWARDS

calculating reward per visit
reward:  0
visits:  5.0
reward per visit = reward / visits =  0.0
state:  0
total_state_rewards (total rewards of each state):  [ 0.  0.  0.  0.  0.]
total_state_visits (total visits of each state):  [ 1.  0.  0.  0.  0.]
state:  1
total_state_rewards (total rewards of each state):  [ 0.  0.  0.  0.  0.]
total_state_visits (total visits of each state):  [ 1.  1.  0.  0.  0.]
state:  2
total_state_rewards (total rewards of each state):  [ 0.  0.  0.  0.  0.]
total_state_visits (total visits of each state):  [ 1.  1.  1.  0.  0.]
state:  1
total_state_rewards (total rewards of each state):  [ 0.  0.  0.  0.  0.]
total_state_visits (total visits of each state):  [ 1.  2.  1.  0.  0.]
state:  0
total_state_rewards (total rewards of each state):  [ 0.  0.  0.  0.  0.]
total_state_visits (total visits of each state):  [ 2.  2.  1.  0.  0.]

calculating reward per visit
reward:  0
visits:  3.0
reward per visit = reward / visits =  0.0
state:  0
total_state_rewards (total rewards of each state):  [ 0.  0.  0.  0.  0.]
total_state_visits (total visits of each state):  [ 3.  2.  1.  0.  0.]
state:  1
total_state_rewards (total rewards of each state):  [ 0.  0.  0.  0.  0.]
total_state_visits (total visits of each state):  [ 3.  3.  1.  0.  0.]
state:  2
total_state_rewards (total rewards of each state):  [ 0.  0.  0.  0.  0.]
total_state_visits (total visits of each state):  [ 3.  3.  2.  0.  0.]

calculating reward per visit
reward:  0
visits:  2.0
reward per visit = reward / visits =  0.0
state:  3
total_state_rewards (total rewards of each state):  [ 0.  0.  0.  0.  0.]
total_state_visits (total visits of each state):  [ 3.  3.  2.  1.  0.]
state:  3
total_state_rewards (total rewards of each state):  [ 0.  0.  0.  0.  0.]
total_state_visits (total visits of each state):  [ 3.  3.  2.  2.  0.]

calculating reward per visit
reward:  1
visits:  2.0
reward per visit = reward / visits =  0.5
state:  4
total_state_rewards (total rewards of each state):  [ 0.   0.   0.   0.   0.5]
total_state_visits (total visits of each state):  [ 3.  3.  2.  2.  1.]
state:  4
total_state_rewards (total rewards of each state):  [ 0.  0.  0.  0.  1.]
total_state_visits (total visits of each state):  [ 3.  3.  2.  2.  2.]
average rewards of each state = total rewards of each state / total visits of each state =  [ 0.   0.   0.   0.   0.5]
COMPUTING TRANSITIONS
state:  0  action:  0  state_:  1
transition_count [state][action][state_]:  0 0 1
[[[ 0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]]
state:  1  action:  0  state_:  2
transition_count [state][action][state_]:  1 0 2
[[[ 0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  1.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]]
state:  2  action:  1  state_:  1
transition_count [state][action][state_]:  2 1 1
[[[ 0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  1.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  1.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]]
state:  1  action:  1  state_:  0
transition_count [state][action][state_]:  1 1 0
[[[ 0.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  1.  0.  0.]
  [ 1.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  1.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]]
state:  0  action:  1  state_:  3
transition_count [state][action][state_]:  0 1 3
[[[ 0.  1.  0.  0.  0.]
  [ 0.  0.  0.  1.  0.]]

 [[ 0.  0.  1.  0.  0.]
  [ 1.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  1.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]]
state:  0  action:  0  state_:  1
transition_count [state][action][state_]:  0 0 1
[[[ 0.  2.  0.  0.  0.]
  [ 0.  0.  0.  1.  0.]]

 [[ 0.  0.  1.  0.  0.]
  [ 1.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  1.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]]
state:  1  action:  0  state_:  2
transition_count [state][action][state_]:  1 0 2
[[[ 0.  2.  0.  0.  0.]
  [ 0.  0.  0.  1.  0.]]

 [[ 0.  0.  2.  0.  0.]
  [ 1.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  1.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]]
state:  2  action:  0  state_:  4
transition_count [state][action][state_]:  2 0 4
[[[ 0.  2.  0.  0.  0.]
  [ 0.  0.  0.  1.  0.]]

 [[ 0.  0.  2.  0.  0.]
  [ 1.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  1.]
  [ 0.  1.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]]
state:  3  action:  1  state_:  3
transition_count [state][action][state_]:  3 1 3
[[[ 0.  2.  0.  0.  0.]
  [ 0.  0.  0.  1.  0.]]

 [[ 0.  0.  2.  0.  0.]
  [ 1.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  1.]
  [ 0.  1.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  1.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]]
state:  3  action:  0  state_:  3
transition_count [state][action][state_]:  3 0 3
[[[ 0.  2.  0.  0.  0.]
  [ 0.  0.  0.  1.  0.]]

 [[ 0.  0.  2.  0.  0.]
  [ 1.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  1.]
  [ 0.  1.  0.  0.  0.]]

 [[ 0.  0.  0.  1.  0.]
  [ 0.  0.  0.  1.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.]]]
state:  4  action:  1  state_:  4
transition_count [state][action][state_]:  4 1 4
[[[ 0.  2.  0.  0.  0.]
  [ 0.  0.  0.  1.  0.]]

 [[ 0.  0.  2.  0.  0.]
  [ 1.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  1.]
  [ 0.  1.  0.  0.  0.]]

 [[ 0.  0.  0.  1.  0.]
  [ 0.  0.  0.  1.  0.]]

 [[ 0.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  1.]]]
state:  4  action:  0  state_:  4
transition_count [state][action][state_]:  4 0 4
[[[ 0.  2.  0.  0.  0.]
  [ 0.  0.  0.  1.  0.]]

 [[ 0.  0.  2.  0.  0.]
  [ 1.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  1.]
  [ 0.  1.  0.  0.  0.]]

 [[ 0.  0.  0.  1.  0.]
  [ 0.  0.  0.  1.  0.]]

 [[ 0.  0.  0.  0.  1.]
  [ 0.  0.  0.  0.  1.]]]
state:  0
action:  0
transition_count[state][action]:  [ 0.  2.  0.  0.  0.]
total_transitions:  2.0
P[state][action]:  [ 0.  1.  0.  0.  0.]

state:  0
action:  1
transition_count[state][action]:  [ 0.  0.  0.  1.  0.]
total_transitions:  1.0
P[state][action]:  [ 0.  0.  0.  1.  0.]

state:  1
action:  0
transition_count[state][action]:  [ 0.  0.  2.  0.  0.]
total_transitions:  2.0
P[state][action]:  [ 0.  0.  1.  0.  0.]

state:  1
action:  1
transition_count[state][action]:  [ 1.  0.  0.  0.  0.]
total_transitions:  1.0
P[state][action]:  [ 1.  0.  0.  0.  0.]

state:  2
action:  0
transition_count[state][action]:  [ 0.  0.  0.  0.  1.]
total_transitions:  1.0
P[state][action]:  [ 0.  0.  0.  0.  1.]

state:  2
action:  1
transition_count[state][action]:  [ 0.  1.  0.  0.  0.]
total_transitions:  1.0
P[state][action]:  [ 0.  1.  0.  0.  0.]

state:  3
action:  0
transition_count[state][action]:  [ 0.  0.  0.  1.  0.]
total_transitions:  1.0
P[state][action]:  [ 0.  0.  0.  1.  0.]

state:  3
action:  1
transition_count[state][action]:  [ 0.  0.  0.  1.  0.]
total_transitions:  1.0
P[state][action]:  [ 0.  0.  0.  1.  0.]

state:  4
action:  0
transition_count[state][action]:  [ 0.  0.  0.  0.  1.]
total_transitions:  1.0
P[state][action]:  [ 0.  0.  0.  0.  1.]

state:  4
action:  1
transition_count[state][action]:  [ 0.  0.  0.  0.  1.]
total_transitions:  1.0
P[state][action]:  [ 0.  0.  0.  0.  1.]

COMPUTING POLICY
iteration: 1 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  1
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  2
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  4
rewards[state]:  0.5
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.5

iteration: 2 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  1
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.45
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  2
rewards[state]:  0.0
state_value:  0.45
state_values[state] = rewards[state] + state_value =  0.45

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.45
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.45
state:  4
rewards[state]:  0.5
state_value:  0.45
state_values[state] = rewards[state] + state_value =  0.95

iteration: 3 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.405
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.405
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.405
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  1
rewards[state]:  0.0
state_value:  0.405
state_values[state] = rewards[state] + state_value =  0.405

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.855
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.3645
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.3645
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.3645
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.3645
state:  2
rewards[state]:  0.0
state_value:  0.855
state_values[state] = rewards[state] + state_value =  0.855

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.855
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.855
state:  4
rewards[state]:  0.5
state_value:  0.855
state_values[state] = rewards[state] + state_value =  1.355

iteration: 4 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.3645
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.3645
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.3645
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.3645
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  0.3645
state_values[state] = rewards[state] + state_value =  0.3645

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.7695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.7695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.7695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.32805
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.32805
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.32805
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.32805
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.32805
state:  1
rewards[state]:  0.0
state_value:  0.7695
state_values[state] = rewards[state] + state_value =  0.7695

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.2195
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.69255
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.69255
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.69255
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.69255
state:  2
rewards[state]:  0.0
state_value:  1.2195
state_values[state] = rewards[state] + state_value =  1.2195

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.2195
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.2195
state:  4
rewards[state]:  0.5
state_value:  1.2195
state_values[state] = rewards[state] + state_value =  1.7195

iteration: 5 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.69255
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.69255
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.69255
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.69255
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  0.69255
state_values[state] = rewards[state] + state_value =  0.69255

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.09755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.09755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.09755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.623295
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.623295
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.623295
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.623295
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.623295
state:  1
rewards[state]:  0.0
state_value:  1.09755
state_values[state] = rewards[state] + state_value =  1.09755

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.54755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.987795
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.987795
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.987795
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.987795
state:  2
rewards[state]:  0.0
state_value:  1.54755
state_values[state] = rewards[state] + state_value =  1.54755

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.54755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.54755
state:  4
rewards[state]:  0.5
state_value:  1.54755
state_values[state] = rewards[state] + state_value =  2.04755

iteration: 6 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.987795
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.987795
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.987795
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.987795
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  0.987795
state_values[state] = rewards[state] + state_value =  0.987795

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.392795
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.392795
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.392795
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.8890155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.8890155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.8890155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.8890155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.8890155
state:  1
rewards[state]:  0.0
state_value:  1.392795
state_values[state] = rewards[state] + state_value =  1.392795

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.842795
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.2535155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.2535155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.2535155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.2535155
state:  2
rewards[state]:  0.0
state_value:  1.842795
state_values[state] = rewards[state] + state_value =  1.842795

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.842795
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.842795
state:  4
rewards[state]:  0.5
state_value:  1.842795
state_values[state] = rewards[state] + state_value =  2.342795

iteration: 7 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.2535155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.2535155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.2535155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.2535155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  1.2535155
state_values[state] = rewards[state] + state_value =  1.2535155

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.6585155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.6585155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.6585155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.12816395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.12816395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.12816395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.12816395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.12816395
state:  1
rewards[state]:  0.0
state_value:  1.6585155
state_values[state] = rewards[state] + state_value =  1.6585155

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.1085155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.49266395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.49266395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.49266395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.49266395
state:  2
rewards[state]:  0.0
state_value:  2.1085155
state_values[state] = rewards[state] + state_value =  2.1085155

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.1085155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.1085155
state:  4
rewards[state]:  0.5
state_value:  2.1085155
state_values[state] = rewards[state] + state_value =  2.6085155

iteration: 8 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.49266395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.49266395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.49266395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.49266395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  1.49266395
state_values[state] = rewards[state] + state_value =  1.49266395

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.89766395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.89766395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.89766395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.343397555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.343397555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.343397555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.343397555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.343397555
state:  1
rewards[state]:  0.0
state_value:  1.89766395
state_values[state] = rewards[state] + state_value =  1.89766395

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.34766395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.707897555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.707897555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.707897555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.707897555
state:  2
rewards[state]:  0.0
state_value:  2.34766395
state_values[state] = rewards[state] + state_value =  2.34766395

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.34766395
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.34766395
state:  4
rewards[state]:  0.5
state_value:  2.34766395
state_values[state] = rewards[state] + state_value =  2.84766395

iteration: 9 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.707897555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.707897555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.707897555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.707897555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  1.707897555
state_values[state] = rewards[state] + state_value =  1.707897555

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.112897555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.112897555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.112897555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.5371077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.5371077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.5371077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.5371077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.5371077995
state:  1
rewards[state]:  0.0
state_value:  2.112897555
state_values[state] = rewards[state] + state_value =  2.112897555

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.562897555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.9016077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.9016077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.9016077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.9016077995
state:  2
rewards[state]:  0.0
state_value:  2.562897555
state_values[state] = rewards[state] + state_value =  2.562897555

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.562897555
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.562897555
state:  4
rewards[state]:  0.5
state_value:  2.562897555
state_values[state] = rewards[state] + state_value =  3.062897555

iteration: 10 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.9016077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.9016077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.9016077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.9016077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  1.9016077995
state_values[state] = rewards[state] + state_value =  1.9016077995

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.3066077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.3066077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.3066077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.71144701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.71144701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.71144701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.71144701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.71144701955
state:  1
rewards[state]:  0.0
state_value:  2.3066077995
state_values[state] = rewards[state] + state_value =  2.3066077995

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.7566077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.07594701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.07594701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.07594701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.07594701955
state:  2
rewards[state]:  0.0
state_value:  2.7566077995
state_values[state] = rewards[state] + state_value =  2.7566077995

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.7566077995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.7566077995
state:  4
rewards[state]:  0.5
state_value:  2.7566077995
state_values[state] = rewards[state] + state_value =  3.2566077995

iteration: 11 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.07594701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.07594701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.07594701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.07594701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  2.07594701955
state_values[state] = rewards[state] + state_value =  2.07594701955

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.48094701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.48094701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.48094701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.8683523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.8683523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.8683523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.8683523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  1.8683523176
state:  1
rewards[state]:  0.0
state_value:  2.48094701955
state_values[state] = rewards[state] + state_value =  2.48094701955

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.93094701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.2328523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.2328523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.2328523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.2328523176
state:  2
rewards[state]:  0.0
state_value:  2.93094701955
state_values[state] = rewards[state] + state_value =  2.93094701955

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.93094701955
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.93094701955
state:  4
rewards[state]:  0.5
state_value:  2.93094701955
state_values[state] = rewards[state] + state_value =  3.43094701955

iteration: 12 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.2328523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.2328523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.2328523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.2328523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  2.2328523176
state_values[state] = rewards[state] + state_value =  2.2328523176

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.6378523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.6378523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.6378523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.00956708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.00956708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.00956708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.00956708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.00956708584
state:  1
rewards[state]:  0.0
state_value:  2.6378523176
state_values[state] = rewards[state] + state_value =  2.6378523176

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.0878523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.37406708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.37406708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.37406708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.37406708584
state:  2
rewards[state]:  0.0
state_value:  3.0878523176
state_values[state] = rewards[state] + state_value =  3.0878523176

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.0878523176
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.0878523176
state:  4
rewards[state]:  0.5
state_value:  3.0878523176
state_values[state] = rewards[state] + state_value =  3.5878523176

iteration: 13 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.37406708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.37406708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.37406708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.37406708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  2.37406708584
state_values[state] = rewards[state] + state_value =  2.37406708584

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.77906708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.77906708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.77906708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.13666037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.13666037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.13666037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.13666037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.13666037725
state:  1
rewards[state]:  0.0
state_value:  2.77906708584
state_values[state] = rewards[state] + state_value =  2.77906708584

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22906708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.50116037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.50116037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.50116037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.50116037725
state:  2
rewards[state]:  0.0
state_value:  3.22906708584
state_values[state] = rewards[state] + state_value =  3.22906708584

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22906708584
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22906708584
state:  4
rewards[state]:  0.5
state_value:  3.22906708584
state_values[state] = rewards[state] + state_value =  3.72906708584

iteration: 14 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.50116037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.50116037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.50116037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.50116037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  2.50116037725
state_values[state] = rewards[state] + state_value =  2.50116037725

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.90616037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.90616037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.90616037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.25104433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.25104433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.25104433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.25104433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.25104433953
state:  1
rewards[state]:  0.0
state_value:  2.90616037725
state_values[state] = rewards[state] + state_value =  2.90616037725

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.35616037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.61554433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.61554433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.61554433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.61554433953
state:  2
rewards[state]:  0.0
state_value:  3.35616037725
state_values[state] = rewards[state] + state_value =  3.35616037725

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.35616037725
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.35616037725
state:  4
rewards[state]:  0.5
state_value:  3.35616037725
state_values[state] = rewards[state] + state_value =  3.85616037725

iteration: 15 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.61554433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.61554433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.61554433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.61554433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  2.61554433953
state_values[state] = rewards[state] + state_value =  2.61554433953

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.02054433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.02054433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.02054433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.35398990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.35398990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.35398990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.35398990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.35398990557
state:  1
rewards[state]:  0.0
state_value:  3.02054433953
state_values[state] = rewards[state] + state_value =  3.02054433953

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.47054433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.71848990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.71848990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.71848990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.71848990557
state:  2
rewards[state]:  0.0
state_value:  3.47054433953
state_values[state] = rewards[state] + state_value =  3.47054433953

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.47054433953
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.47054433953
state:  4
rewards[state]:  0.5
state_value:  3.47054433953
state_values[state] = rewards[state] + state_value =  3.97054433953

iteration: 16 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.71848990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.71848990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.71848990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.71848990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  2.71848990557
state_values[state] = rewards[state] + state_value =  2.71848990557

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.12348990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.12348990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.12348990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.44664091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.44664091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.44664091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.44664091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.44664091502
state:  1
rewards[state]:  0.0
state_value:  3.12348990557
state_values[state] = rewards[state] + state_value =  3.12348990557

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57348990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.81114091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.81114091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.81114091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.81114091502
state:  2
rewards[state]:  0.0
state_value:  3.57348990557
state_values[state] = rewards[state] + state_value =  3.57348990557

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57348990557
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57348990557
state:  4
rewards[state]:  0.5
state_value:  3.57348990557
state_values[state] = rewards[state] + state_value =  4.07348990557

iteration: 17 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.81114091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.81114091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.81114091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.81114091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  2.81114091502
state_values[state] = rewards[state] + state_value =  2.81114091502

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.21614091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.21614091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.21614091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.53002682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.53002682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.53002682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.53002682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.53002682352
state:  1
rewards[state]:  0.0
state_value:  3.21614091502
state_values[state] = rewards[state] + state_value =  3.21614091502

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.66614091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.89452682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.89452682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.89452682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.89452682352
state:  2
rewards[state]:  0.0
state_value:  3.66614091502
state_values[state] = rewards[state] + state_value =  3.66614091502

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.66614091502
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.66614091502
state:  4
rewards[state]:  0.5
state_value:  3.66614091502
state_values[state] = rewards[state] + state_value =  4.16614091502

iteration: 18 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.89452682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.89452682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.89452682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.89452682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  2.89452682352
state_values[state] = rewards[state] + state_value =  2.89452682352

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.29952682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.29952682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.29952682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.60507414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.60507414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.60507414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.60507414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.60507414116
state:  1
rewards[state]:  0.0
state_value:  3.29952682352
state_values[state] = rewards[state] + state_value =  3.29952682352

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.74952682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.96957414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.96957414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.96957414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.96957414116
state:  2
rewards[state]:  0.0
state_value:  3.74952682352
state_values[state] = rewards[state] + state_value =  3.74952682352

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.74952682352
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.74952682352
state:  4
rewards[state]:  0.5
state_value:  3.74952682352
state_values[state] = rewards[state] + state_value =  4.24952682352

iteration: 19 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.96957414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.96957414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.96957414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.96957414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  2.96957414116
state_values[state] = rewards[state] + state_value =  2.96957414116

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.37457414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.37457414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.37457414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.67261672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.67261672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.67261672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.67261672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.67261672705
state:  1
rewards[state]:  0.0
state_value:  3.37457414116
state_values[state] = rewards[state] + state_value =  3.37457414116

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.82457414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.03711672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.03711672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.03711672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.03711672705
state:  2
rewards[state]:  0.0
state_value:  3.82457414116
state_values[state] = rewards[state] + state_value =  3.82457414116

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.82457414116
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.82457414116
state:  4
rewards[state]:  0.5
state_value:  3.82457414116
state_values[state] = rewards[state] + state_value =  4.32457414116

iteration: 20 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.03711672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.03711672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.03711672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.03711672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.03711672705
state_values[state] = rewards[state] + state_value =  3.03711672705

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.44211672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.44211672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.44211672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.73340505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.73340505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.73340505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.73340505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.73340505434
state:  1
rewards[state]:  0.0
state_value:  3.44211672705
state_values[state] = rewards[state] + state_value =  3.44211672705

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.89211672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.09790505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.09790505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.09790505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.09790505434
state:  2
rewards[state]:  0.0
state_value:  3.89211672705
state_values[state] = rewards[state] + state_value =  3.89211672705

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.89211672705
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.89211672705
state:  4
rewards[state]:  0.5
state_value:  3.89211672705
state_values[state] = rewards[state] + state_value =  4.39211672705

iteration: 21 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.09790505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.09790505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.09790505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.09790505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.09790505434
state_values[state] = rewards[state] + state_value =  3.09790505434

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.50290505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.50290505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.50290505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.78811454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.78811454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.78811454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.78811454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.78811454891
state:  1
rewards[state]:  0.0
state_value:  3.50290505434
state_values[state] = rewards[state] + state_value =  3.50290505434

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.95290505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15261454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15261454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15261454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15261454891
state:  2
rewards[state]:  0.0
state_value:  3.95290505434
state_values[state] = rewards[state] + state_value =  3.95290505434

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.95290505434
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.95290505434
state:  4
rewards[state]:  0.5
state_value:  3.95290505434
state_values[state] = rewards[state] + state_value =  4.45290505434

iteration: 22 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15261454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15261454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15261454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15261454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.15261454891
state_values[state] = rewards[state] + state_value =  3.15261454891

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.55761454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.55761454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.55761454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.83735309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.83735309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.83735309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.83735309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.83735309402
state:  1
rewards[state]:  0.0
state_value:  3.55761454891
state_values[state] = rewards[state] + state_value =  3.55761454891

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.00761454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20185309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20185309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20185309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20185309402
state:  2
rewards[state]:  0.0
state_value:  4.00761454891
state_values[state] = rewards[state] + state_value =  4.00761454891

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.00761454891
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.00761454891
state:  4
rewards[state]:  0.5
state_value:  4.00761454891
state_values[state] = rewards[state] + state_value =  4.50761454891

iteration: 23 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20185309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20185309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20185309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20185309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.20185309402
state_values[state] = rewards[state] + state_value =  3.20185309402

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60685309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60685309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60685309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.88166778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.88166778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.88166778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.88166778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.88166778462
state:  1
rewards[state]:  0.0
state_value:  3.60685309402
state_values[state] = rewards[state] + state_value =  3.60685309402

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.05685309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24616778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24616778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24616778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24616778462
state:  2
rewards[state]:  0.0
state_value:  4.05685309402
state_values[state] = rewards[state] + state_value =  4.05685309402

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.05685309402
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.05685309402
state:  4
rewards[state]:  0.5
state_value:  4.05685309402
state_values[state] = rewards[state] + state_value =  4.55685309402

iteration: 24 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24616778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24616778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24616778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24616778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.24616778462
state_values[state] = rewards[state] + state_value =  3.24616778462

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.65116778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.65116778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.65116778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.92155100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.92155100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.92155100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.92155100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.92155100615
state:  1
rewards[state]:  0.0
state_value:  3.65116778462
state_values[state] = rewards[state] + state_value =  3.65116778462

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.10116778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28605100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28605100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28605100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28605100615
state:  2
rewards[state]:  0.0
state_value:  4.10116778462
state_values[state] = rewards[state] + state_value =  4.10116778462

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.10116778462
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.10116778462
state:  4
rewards[state]:  0.5
state_value:  4.10116778462
state_values[state] = rewards[state] + state_value =  4.60116778462

iteration: 25 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28605100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28605100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28605100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28605100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.28605100615
state_values[state] = rewards[state] + state_value =  3.28605100615

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.69105100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.69105100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.69105100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.95744590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.95744590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.95744590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.95744590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.95744590554
state:  1
rewards[state]:  0.0
state_value:  3.69105100615
state_values[state] = rewards[state] + state_value =  3.69105100615

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.14105100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.32194590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.32194590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.32194590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.32194590554
state:  2
rewards[state]:  0.0
state_value:  4.14105100615
state_values[state] = rewards[state] + state_value =  4.14105100615

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.14105100615
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.14105100615
state:  4
rewards[state]:  0.5
state_value:  4.14105100615
state_values[state] = rewards[state] + state_value =  4.64105100615

iteration: 26 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.32194590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.32194590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.32194590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.32194590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.32194590554
state_values[state] = rewards[state] + state_value =  3.32194590554

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.72694590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.72694590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.72694590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.98975131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.98975131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.98975131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.98975131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  2.98975131498
state:  1
rewards[state]:  0.0
state_value:  3.72694590554
state_values[state] = rewards[state] + state_value =  3.72694590554

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.17694590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.35425131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.35425131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.35425131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.35425131498
state:  2
rewards[state]:  0.0
state_value:  4.17694590554
state_values[state] = rewards[state] + state_value =  4.17694590554

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.17694590554
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.17694590554
state:  4
rewards[state]:  0.5
state_value:  4.17694590554
state_values[state] = rewards[state] + state_value =  4.67694590554

iteration: 27 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.35425131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.35425131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.35425131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.35425131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.35425131498
state_values[state] = rewards[state] + state_value =  3.35425131498

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.75925131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.75925131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.75925131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.01882618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.01882618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.01882618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.01882618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.01882618349
state:  1
rewards[state]:  0.0
state_value:  3.75925131498
state_values[state] = rewards[state] + state_value =  3.75925131498

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.20925131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.38332618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.38332618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.38332618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.38332618349
state:  2
rewards[state]:  0.0
state_value:  4.20925131498
state_values[state] = rewards[state] + state_value =  4.20925131498

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.20925131498
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.20925131498
state:  4
rewards[state]:  0.5
state_value:  4.20925131498
state_values[state] = rewards[state] + state_value =  4.70925131498

iteration: 28 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.38332618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.38332618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.38332618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.38332618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.38332618349
state_values[state] = rewards[state] + state_value =  3.38332618349

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.78832618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.78832618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.78832618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.04499356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.04499356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.04499356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.04499356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.04499356514
state:  1
rewards[state]:  0.0
state_value:  3.78832618349
state_values[state] = rewards[state] + state_value =  3.78832618349

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.23832618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.40949356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.40949356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.40949356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.40949356514
state:  2
rewards[state]:  0.0
state_value:  4.23832618349
state_values[state] = rewards[state] + state_value =  4.23832618349

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.23832618349
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.23832618349
state:  4
rewards[state]:  0.5
state_value:  4.23832618349
state_values[state] = rewards[state] + state_value =  4.73832618349

iteration: 29 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.40949356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.40949356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.40949356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.40949356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.40949356514
state_values[state] = rewards[state] + state_value =  3.40949356514

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.81449356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.81449356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.81449356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.06854420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.06854420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.06854420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.06854420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.06854420862
state:  1
rewards[state]:  0.0
state_value:  3.81449356514
state_values[state] = rewards[state] + state_value =  3.81449356514

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.26449356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.43304420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.43304420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.43304420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.43304420862
state:  2
rewards[state]:  0.0
state_value:  4.26449356514
state_values[state] = rewards[state] + state_value =  4.26449356514

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.26449356514
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.26449356514
state:  4
rewards[state]:  0.5
state_value:  4.26449356514
state_values[state] = rewards[state] + state_value =  4.76449356514

iteration: 30 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.43304420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.43304420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.43304420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.43304420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.43304420862
state_values[state] = rewards[state] + state_value =  3.43304420862

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.83804420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.83804420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.83804420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.08973978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.08973978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.08973978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.08973978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.08973978776
state:  1
rewards[state]:  0.0
state_value:  3.83804420862
state_values[state] = rewards[state] + state_value =  3.83804420862

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.28804420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.45423978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.45423978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.45423978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.45423978776
state:  2
rewards[state]:  0.0
state_value:  4.28804420862
state_values[state] = rewards[state] + state_value =  4.28804420862

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.28804420862
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.28804420862
state:  4
rewards[state]:  0.5
state_value:  4.28804420862
state_values[state] = rewards[state] + state_value =  4.78804420862

iteration: 31 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.45423978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.45423978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.45423978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.45423978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.45423978776
state_values[state] = rewards[state] + state_value =  3.45423978776

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.85923978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.85923978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.85923978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.10881580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.10881580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.10881580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.10881580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.10881580899
state:  1
rewards[state]:  0.0
state_value:  3.85923978776
state_values[state] = rewards[state] + state_value =  3.85923978776

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.30923978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.47331580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.47331580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.47331580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.47331580899
state:  2
rewards[state]:  0.0
state_value:  4.30923978776
state_values[state] = rewards[state] + state_value =  4.30923978776

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.30923978776
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.30923978776
state:  4
rewards[state]:  0.5
state_value:  4.30923978776
state_values[state] = rewards[state] + state_value =  4.80923978776

iteration: 32 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.47331580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.47331580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.47331580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.47331580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.47331580899
state_values[state] = rewards[state] + state_value =  3.47331580899

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.87831580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.87831580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.87831580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.12598422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.12598422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.12598422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.12598422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.12598422809
state:  1
rewards[state]:  0.0
state_value:  3.87831580899
state_values[state] = rewards[state] + state_value =  3.87831580899

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.32831580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.49048422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.49048422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.49048422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.49048422809
state:  2
rewards[state]:  0.0
state_value:  4.32831580899
state_values[state] = rewards[state] + state_value =  4.32831580899

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.32831580899
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.32831580899
state:  4
rewards[state]:  0.5
state_value:  4.32831580899
state_values[state] = rewards[state] + state_value =  4.82831580899

iteration: 33 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.49048422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.49048422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.49048422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.49048422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.49048422809
state_values[state] = rewards[state] + state_value =  3.49048422809

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.89548422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.89548422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.89548422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.14143580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.14143580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.14143580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.14143580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.14143580528
state:  1
rewards[state]:  0.0
state_value:  3.89548422809
state_values[state] = rewards[state] + state_value =  3.89548422809

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.34548422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.50593580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.50593580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.50593580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.50593580528
state:  2
rewards[state]:  0.0
state_value:  4.34548422809
state_values[state] = rewards[state] + state_value =  4.34548422809

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.34548422809
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.34548422809
state:  4
rewards[state]:  0.5
state_value:  4.34548422809
state_values[state] = rewards[state] + state_value =  4.84548422809

iteration: 34 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.50593580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.50593580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.50593580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.50593580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.50593580528
state_values[state] = rewards[state] + state_value =  3.50593580528

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.91093580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.91093580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.91093580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15534222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15534222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15534222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15534222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.15534222475
state:  1
rewards[state]:  0.0
state_value:  3.91093580528
state_values[state] = rewards[state] + state_value =  3.91093580528

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.36093580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.51984222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.51984222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.51984222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.51984222475
state:  2
rewards[state]:  0.0
state_value:  4.36093580528
state_values[state] = rewards[state] + state_value =  4.36093580528

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.36093580528
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.36093580528
state:  4
rewards[state]:  0.5
state_value:  4.36093580528
state_values[state] = rewards[state] + state_value =  4.86093580528

iteration: 35 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.51984222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.51984222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.51984222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.51984222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.51984222475
state_values[state] = rewards[state] + state_value =  3.51984222475

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.92484222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.92484222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.92484222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.16785800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.16785800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.16785800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.16785800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.16785800228
state:  1
rewards[state]:  0.0
state_value:  3.92484222475
state_values[state] = rewards[state] + state_value =  3.92484222475

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.37484222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.53235800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.53235800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.53235800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.53235800228
state:  2
rewards[state]:  0.0
state_value:  4.37484222475
state_values[state] = rewards[state] + state_value =  4.37484222475

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.37484222475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.37484222475
state:  4
rewards[state]:  0.5
state_value:  4.37484222475
state_values[state] = rewards[state] + state_value =  4.87484222475

iteration: 36 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.53235800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.53235800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.53235800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.53235800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.53235800228
state_values[state] = rewards[state] + state_value =  3.53235800228

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.93735800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.93735800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.93735800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.17912220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.17912220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.17912220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.17912220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.17912220205
state:  1
rewards[state]:  0.0
state_value:  3.93735800228
state_values[state] = rewards[state] + state_value =  3.93735800228

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.38735800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.54362220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.54362220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.54362220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.54362220205
state:  2
rewards[state]:  0.0
state_value:  4.38735800228
state_values[state] = rewards[state] + state_value =  4.38735800228

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.38735800228
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.38735800228
state:  4
rewards[state]:  0.5
state_value:  4.38735800228
state_values[state] = rewards[state] + state_value =  4.88735800228

iteration: 37 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.54362220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.54362220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.54362220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.54362220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.54362220205
state_values[state] = rewards[state] + state_value =  3.54362220205

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.94862220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.94862220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.94862220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.18925998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.18925998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.18925998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.18925998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.18925998184
state:  1
rewards[state]:  0.0
state_value:  3.94862220205
state_values[state] = rewards[state] + state_value =  3.94862220205

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.39862220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.55375998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.55375998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.55375998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.55375998184
state:  2
rewards[state]:  0.0
state_value:  4.39862220205
state_values[state] = rewards[state] + state_value =  4.39862220205

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.39862220205
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.39862220205
state:  4
rewards[state]:  0.5
state_value:  4.39862220205
state_values[state] = rewards[state] + state_value =  4.89862220205

iteration: 38 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.55375998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.55375998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.55375998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.55375998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.55375998184
state_values[state] = rewards[state] + state_value =  3.55375998184

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.95875998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.95875998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.95875998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.19838398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.19838398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.19838398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.19838398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.19838398366
state:  1
rewards[state]:  0.0
state_value:  3.95875998184
state_values[state] = rewards[state] + state_value =  3.95875998184

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.40875998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.56288398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.56288398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.56288398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.56288398366
state:  2
rewards[state]:  0.0
state_value:  4.40875998184
state_values[state] = rewards[state] + state_value =  4.40875998184

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.40875998184
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.40875998184
state:  4
rewards[state]:  0.5
state_value:  4.40875998184
state_values[state] = rewards[state] + state_value =  4.90875998184

iteration: 39 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.56288398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.56288398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.56288398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.56288398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.56288398366
state_values[state] = rewards[state] + state_value =  3.56288398366

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.96788398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.96788398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.96788398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20659558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20659558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20659558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20659558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.20659558529
state:  1
rewards[state]:  0.0
state_value:  3.96788398366
state_values[state] = rewards[state] + state_value =  3.96788398366

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.41788398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57109558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57109558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57109558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57109558529
state:  2
rewards[state]:  0.0
state_value:  4.41788398366
state_values[state] = rewards[state] + state_value =  4.41788398366

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.41788398366
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.41788398366
state:  4
rewards[state]:  0.5
state_value:  4.41788398366
state_values[state] = rewards[state] + state_value =  4.91788398366

iteration: 40 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57109558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57109558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57109558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57109558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.57109558529
state_values[state] = rewards[state] + state_value =  3.57109558529

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.97609558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.97609558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.97609558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.21398602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.21398602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.21398602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.21398602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.21398602676
state:  1
rewards[state]:  0.0
state_value:  3.97609558529
state_values[state] = rewards[state] + state_value =  3.97609558529

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.42609558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57848602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57848602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57848602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57848602676
state:  2
rewards[state]:  0.0
state_value:  4.42609558529
state_values[state] = rewards[state] + state_value =  4.42609558529

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.42609558529
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.42609558529
state:  4
rewards[state]:  0.5
state_value:  4.42609558529
state_values[state] = rewards[state] + state_value =  4.92609558529

iteration: 41 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57848602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57848602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57848602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.57848602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.57848602676
state_values[state] = rewards[state] + state_value =  3.57848602676

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.98348602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.98348602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.98348602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22063742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22063742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22063742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22063742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22063742409
state:  1
rewards[state]:  0.0
state_value:  3.98348602676
state_values[state] = rewards[state] + state_value =  3.98348602676

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.43348602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.58513742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.58513742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.58513742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.58513742409
state:  2
rewards[state]:  0.0
state_value:  4.43348602676
state_values[state] = rewards[state] + state_value =  4.43348602676

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.43348602676
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.43348602676
state:  4
rewards[state]:  0.5
state_value:  4.43348602676
state_values[state] = rewards[state] + state_value =  4.93348602676

iteration: 42 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.58513742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.58513742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.58513742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.58513742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.58513742409
state_values[state] = rewards[state] + state_value =  3.58513742409

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.99013742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.99013742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.99013742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22662368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22662368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22662368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22662368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.22662368168
state:  1
rewards[state]:  0.0
state_value:  3.99013742409
state_values[state] = rewards[state] + state_value =  3.99013742409

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.44013742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59112368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59112368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59112368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59112368168
state:  2
rewards[state]:  0.0
state_value:  4.44013742409
state_values[state] = rewards[state] + state_value =  4.44013742409

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.44013742409
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.44013742409
state:  4
rewards[state]:  0.5
state_value:  4.44013742409
state_values[state] = rewards[state] + state_value =  4.94013742409

iteration: 43 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59112368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59112368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59112368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59112368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.59112368168
state_values[state] = rewards[state] + state_value =  3.59112368168

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.99612368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.99612368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.99612368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.23201131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.23201131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.23201131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.23201131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.23201131351
state:  1
rewards[state]:  0.0
state_value:  3.99612368168
state_values[state] = rewards[state] + state_value =  3.99612368168

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.44612368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59651131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59651131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59651131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59651131351
state:  2
rewards[state]:  0.0
state_value:  4.44612368168
state_values[state] = rewards[state] + state_value =  4.44612368168

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.44612368168
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.44612368168
state:  4
rewards[state]:  0.5
state_value:  4.44612368168
state_values[state] = rewards[state] + state_value =  4.94612368168

iteration: 44 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59651131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59651131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59651131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.59651131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.59651131351
state_values[state] = rewards[state] + state_value =  3.59651131351

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.00151131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.00151131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.00151131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.23686018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.23686018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.23686018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.23686018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.23686018216
state:  1
rewards[state]:  0.0
state_value:  4.00151131351
state_values[state] = rewards[state] + state_value =  4.00151131351

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.45151131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60136018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60136018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60136018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60136018216
state:  2
rewards[state]:  0.0
state_value:  4.45151131351
state_values[state] = rewards[state] + state_value =  4.45151131351

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.45151131351
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.45151131351
state:  4
rewards[state]:  0.5
state_value:  4.45151131351
state_values[state] = rewards[state] + state_value =  4.95151131351

iteration: 45 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60136018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60136018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60136018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60136018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.60136018216
state_values[state] = rewards[state] + state_value =  3.60136018216

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.00636018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.00636018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.00636018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24122416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24122416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24122416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24122416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24122416394
state:  1
rewards[state]:  0.0
state_value:  4.00636018216
state_values[state] = rewards[state] + state_value =  4.00636018216

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.45636018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60572416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60572416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60572416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60572416394
state:  2
rewards[state]:  0.0
state_value:  4.45636018216
state_values[state] = rewards[state] + state_value =  4.45636018216

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.45636018216
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.45636018216
state:  4
rewards[state]:  0.5
state_value:  4.45636018216
state_values[state] = rewards[state] + state_value =  4.95636018216

iteration: 46 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60572416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60572416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60572416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60572416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.60572416394
state_values[state] = rewards[state] + state_value =  3.60572416394

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.01072416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.01072416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.01072416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24515174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24515174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24515174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24515174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24515174755
state:  1
rewards[state]:  0.0
state_value:  4.01072416394
state_values[state] = rewards[state] + state_value =  4.01072416394

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.46072416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60965174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60965174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60965174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60965174755
state:  2
rewards[state]:  0.0
state_value:  4.46072416394
state_values[state] = rewards[state] + state_value =  4.46072416394

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.46072416394
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.46072416394
state:  4
rewards[state]:  0.5
state_value:  4.46072416394
state_values[state] = rewards[state] + state_value =  4.96072416394

iteration: 47 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60965174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60965174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60965174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.60965174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.60965174755
state_values[state] = rewards[state] + state_value =  3.60965174755

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.01465174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.01465174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.01465174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24868657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24868657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24868657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24868657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.24868657279
state:  1
rewards[state]:  0.0
state_value:  4.01465174755
state_values[state] = rewards[state] + state_value =  4.01465174755

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.46465174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61318657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61318657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61318657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61318657279
state:  2
rewards[state]:  0.0
state_value:  4.46465174755
state_values[state] = rewards[state] + state_value =  4.46465174755

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.46465174755
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.46465174755
state:  4
rewards[state]:  0.5
state_value:  4.46465174755
state_values[state] = rewards[state] + state_value =  4.96465174755

iteration: 48 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61318657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61318657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61318657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61318657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.61318657279
state_values[state] = rewards[state] + state_value =  3.61318657279

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.01818657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.01818657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.01818657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25186791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25186791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25186791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25186791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25186791551
state:  1
rewards[state]:  0.0
state_value:  4.01818657279
state_values[state] = rewards[state] + state_value =  4.01818657279

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.46818657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61636791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61636791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61636791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61636791551
state:  2
rewards[state]:  0.0
state_value:  4.46818657279
state_values[state] = rewards[state] + state_value =  4.46818657279

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.46818657279
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.46818657279
state:  4
rewards[state]:  0.5
state_value:  4.46818657279
state_values[state] = rewards[state] + state_value =  4.96818657279

iteration: 49 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61636791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61636791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61636791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61636791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.61636791551
state_values[state] = rewards[state] + state_value =  3.61636791551

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.02136791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.02136791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.02136791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25473112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25473112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25473112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25473112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25473112396
state:  1
rewards[state]:  0.0
state_value:  4.02136791551
state_values[state] = rewards[state] + state_value =  4.02136791551

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.47136791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61923112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61923112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61923112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61923112396
state:  2
rewards[state]:  0.0
state_value:  4.47136791551
state_values[state] = rewards[state] + state_value =  4.47136791551

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.47136791551
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.47136791551
state:  4
rewards[state]:  0.5
state_value:  4.47136791551
state_values[state] = rewards[state] + state_value =  4.97136791551

iteration: 50 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61923112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61923112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61923112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.61923112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.61923112396
state_values[state] = rewards[state] + state_value =  3.61923112396

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.02423112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.02423112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.02423112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25730801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25730801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25730801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25730801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25730801157
state:  1
rewards[state]:  0.0
state_value:  4.02423112396
state_values[state] = rewards[state] + state_value =  4.02423112396

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.47423112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62180801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62180801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62180801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62180801157
state:  2
rewards[state]:  0.0
state_value:  4.47423112396
state_values[state] = rewards[state] + state_value =  4.47423112396

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.47423112396
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.47423112396
state:  4
rewards[state]:  0.5
state_value:  4.47423112396
state_values[state] = rewards[state] + state_value =  4.97423112396

iteration: 51 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62180801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62180801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62180801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62180801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.62180801157
state_values[state] = rewards[state] + state_value =  3.62180801157

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.02680801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.02680801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.02680801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25962721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25962721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25962721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25962721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.25962721041
state:  1
rewards[state]:  0.0
state_value:  4.02680801157
state_values[state] = rewards[state] + state_value =  4.02680801157

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.47680801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62412721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62412721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62412721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62412721041
state:  2
rewards[state]:  0.0
state_value:  4.47680801157
state_values[state] = rewards[state] + state_value =  4.47680801157

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.47680801157
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.47680801157
state:  4
rewards[state]:  0.5
state_value:  4.47680801157
state_values[state] = rewards[state] + state_value =  4.97680801157

iteration: 52 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62412721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62412721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62412721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62412721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.62412721041
state_values[state] = rewards[state] + state_value =  3.62412721041

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.02912721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.02912721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.02912721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26171448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26171448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26171448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26171448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26171448937
state:  1
rewards[state]:  0.0
state_value:  4.02912721041
state_values[state] = rewards[state] + state_value =  4.02912721041

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.47912721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62621448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62621448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62621448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62621448937
state:  2
rewards[state]:  0.0
state_value:  4.47912721041
state_values[state] = rewards[state] + state_value =  4.47912721041

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.47912721041
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.47912721041
state:  4
rewards[state]:  0.5
state_value:  4.47912721041
state_values[state] = rewards[state] + state_value =  4.97912721041

iteration: 53 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62621448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62621448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62621448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62621448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.62621448937
state_values[state] = rewards[state] + state_value =  3.62621448937

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03121448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03121448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03121448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26359304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26359304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26359304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26359304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26359304043
state:  1
rewards[state]:  0.0
state_value:  4.03121448937
state_values[state] = rewards[state] + state_value =  4.03121448937

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48121448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62809304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62809304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62809304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62809304043
state:  2
rewards[state]:  0.0
state_value:  4.48121448937
state_values[state] = rewards[state] + state_value =  4.48121448937

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48121448937
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48121448937
state:  4
rewards[state]:  0.5
state_value:  4.48121448937
state_values[state] = rewards[state] + state_value =  4.98121448937

iteration: 54 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62809304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62809304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62809304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62809304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.62809304043
state_values[state] = rewards[state] + state_value =  3.62809304043

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03309304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03309304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03309304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26528373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26528373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26528373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26528373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26528373639
state:  1
rewards[state]:  0.0
state_value:  4.03309304043
state_values[state] = rewards[state] + state_value =  4.03309304043

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48309304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62978373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62978373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62978373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62978373639
state:  2
rewards[state]:  0.0
state_value:  4.48309304043
state_values[state] = rewards[state] + state_value =  4.48309304043

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48309304043
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48309304043
state:  4
rewards[state]:  0.5
state_value:  4.48309304043
state_values[state] = rewards[state] + state_value =  4.98309304043

iteration: 55 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62978373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62978373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62978373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.62978373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.62978373639
state_values[state] = rewards[state] + state_value =  3.62978373639

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03478373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03478373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03478373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26680536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26680536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26680536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26680536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26680536275
state:  1
rewards[state]:  0.0
state_value:  4.03478373639
state_values[state] = rewards[state] + state_value =  4.03478373639

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48478373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63130536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63130536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63130536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63130536275
state:  2
rewards[state]:  0.0
state_value:  4.48478373639
state_values[state] = rewards[state] + state_value =  4.48478373639

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48478373639
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48478373639
state:  4
rewards[state]:  0.5
state_value:  4.48478373639
state_values[state] = rewards[state] + state_value =  4.98478373639

iteration: 56 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63130536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63130536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63130536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63130536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.63130536275
state_values[state] = rewards[state] + state_value =  3.63130536275

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03630536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03630536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03630536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26817482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26817482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26817482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26817482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26817482648
state:  1
rewards[state]:  0.0
state_value:  4.03630536275
state_values[state] = rewards[state] + state_value =  4.03630536275

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48630536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63267482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63267482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63267482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63267482648
state:  2
rewards[state]:  0.0
state_value:  4.48630536275
state_values[state] = rewards[state] + state_value =  4.48630536275

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48630536275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48630536275
state:  4
rewards[state]:  0.5
state_value:  4.48630536275
state_values[state] = rewards[state] + state_value =  4.98630536275

iteration: 57 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63267482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63267482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63267482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63267482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.63267482648
state_values[state] = rewards[state] + state_value =  3.63267482648

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03767482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03767482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03767482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26940734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26940734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26940734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26940734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.26940734383
state:  1
rewards[state]:  0.0
state_value:  4.03767482648
state_values[state] = rewards[state] + state_value =  4.03767482648

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48767482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63390734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63390734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63390734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63390734383
state:  2
rewards[state]:  0.0
state_value:  4.48767482648
state_values[state] = rewards[state] + state_value =  4.48767482648

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48767482648
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48767482648
state:  4
rewards[state]:  0.5
state_value:  4.48767482648
state_values[state] = rewards[state] + state_value =  4.98767482648

iteration: 58 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63390734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63390734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63390734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63390734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.63390734383
state_values[state] = rewards[state] + state_value =  3.63390734383

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03890734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03890734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.03890734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27051660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27051660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27051660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27051660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27051660944
state:  1
rewards[state]:  0.0
state_value:  4.03890734383
state_values[state] = rewards[state] + state_value =  4.03890734383

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48890734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63501660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63501660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63501660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63501660944
state:  2
rewards[state]:  0.0
state_value:  4.48890734383
state_values[state] = rewards[state] + state_value =  4.48890734383

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48890734383
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.48890734383
state:  4
rewards[state]:  0.5
state_value:  4.48890734383
state_values[state] = rewards[state] + state_value =  4.98890734383

iteration: 59 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63501660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63501660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63501660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63501660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.63501660944
state_values[state] = rewards[state] + state_value =  3.63501660944

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04001660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04001660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04001660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2715149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2715149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2715149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2715149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2715149485
state:  1
rewards[state]:  0.0
state_value:  4.04001660944
state_values[state] = rewards[state] + state_value =  4.04001660944

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49001660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6360149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6360149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6360149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6360149485
state:  2
rewards[state]:  0.0
state_value:  4.49001660944
state_values[state] = rewards[state] + state_value =  4.49001660944

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49001660944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49001660944
state:  4
rewards[state]:  0.5
state_value:  4.49001660944
state_values[state] = rewards[state] + state_value =  4.99001660944

iteration: 60 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6360149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6360149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6360149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6360149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.6360149485
state_values[state] = rewards[state] + state_value =  3.6360149485

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0410149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0410149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0410149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27241345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27241345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27241345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27241345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27241345365
state:  1
rewards[state]:  0.0
state_value:  4.0410149485
state_values[state] = rewards[state] + state_value =  4.0410149485

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4910149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63691345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63691345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63691345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63691345365
state:  2
rewards[state]:  0.0
state_value:  4.4910149485
state_values[state] = rewards[state] + state_value =  4.4910149485

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4910149485
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4910149485
state:  4
rewards[state]:  0.5
state_value:  4.4910149485
state_values[state] = rewards[state] + state_value =  4.9910149485

iteration: 61 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63691345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63691345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63691345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63691345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.63691345365
state_values[state] = rewards[state] + state_value =  3.63691345365

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04191345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04191345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04191345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27322210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27322210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27322210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27322210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27322210829
state:  1
rewards[state]:  0.0
state_value:  4.04191345365
state_values[state] = rewards[state] + state_value =  4.04191345365

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49191345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63772210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63772210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63772210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63772210829
state:  2
rewards[state]:  0.0
state_value:  4.49191345365
state_values[state] = rewards[state] + state_value =  4.49191345365

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49191345365
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49191345365
state:  4
rewards[state]:  0.5
state_value:  4.49191345365
state_values[state] = rewards[state] + state_value =  4.99191345365

iteration: 62 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63772210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63772210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63772210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63772210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.63772210829
state_values[state] = rewards[state] + state_value =  3.63772210829

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04272210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04272210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04272210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27394989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27394989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27394989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27394989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27394989746
state:  1
rewards[state]:  0.0
state_value:  4.04272210829
state_values[state] = rewards[state] + state_value =  4.04272210829

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49272210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63844989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63844989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63844989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63844989746
state:  2
rewards[state]:  0.0
state_value:  4.49272210829
state_values[state] = rewards[state] + state_value =  4.49272210829

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49272210829
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49272210829
state:  4
rewards[state]:  0.5
state_value:  4.49272210829
state_values[state] = rewards[state] + state_value =  4.99272210829

iteration: 63 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63844989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63844989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63844989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63844989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.63844989746
state_values[state] = rewards[state] + state_value =  3.63844989746

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04344989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04344989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04344989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27460490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27460490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27460490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27460490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27460490771
state:  1
rewards[state]:  0.0
state_value:  4.04344989746
state_values[state] = rewards[state] + state_value =  4.04344989746

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49344989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63910490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63910490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63910490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63910490771
state:  2
rewards[state]:  0.0
state_value:  4.49344989746
state_values[state] = rewards[state] + state_value =  4.49344989746

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49344989746
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49344989746
state:  4
rewards[state]:  0.5
state_value:  4.49344989746
state_values[state] = rewards[state] + state_value =  4.99344989746

iteration: 64 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63910490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63910490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63910490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63910490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.63910490771
state_values[state] = rewards[state] + state_value =  3.63910490771

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04410490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04410490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04410490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27519441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27519441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27519441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27519441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27519441694
state:  1
rewards[state]:  0.0
state_value:  4.04410490771
state_values[state] = rewards[state] + state_value =  4.04410490771

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49410490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63969441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63969441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63969441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63969441694
state:  2
rewards[state]:  0.0
state_value:  4.49410490771
state_values[state] = rewards[state] + state_value =  4.49410490771

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49410490771
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49410490771
state:  4
rewards[state]:  0.5
state_value:  4.49410490771
state_values[state] = rewards[state] + state_value =  4.99410490771

iteration: 65 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63969441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63969441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63969441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.63969441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.63969441694
state_values[state] = rewards[state] + state_value =  3.63969441694

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04469441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04469441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04469441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27572497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27572497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27572497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27572497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27572497525
state:  1
rewards[state]:  0.0
state_value:  4.04469441694
state_values[state] = rewards[state] + state_value =  4.04469441694

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49469441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64022497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64022497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64022497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64022497525
state:  2
rewards[state]:  0.0
state_value:  4.49469441694
state_values[state] = rewards[state] + state_value =  4.49469441694

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49469441694
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49469441694
state:  4
rewards[state]:  0.5
state_value:  4.49469441694
state_values[state] = rewards[state] + state_value =  4.99469441694

iteration: 66 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64022497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64022497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64022497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64022497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64022497525
state_values[state] = rewards[state] + state_value =  3.64022497525

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04522497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04522497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04522497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27620247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27620247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27620247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27620247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27620247772
state:  1
rewards[state]:  0.0
state_value:  4.04522497525
state_values[state] = rewards[state] + state_value =  4.04522497525

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49522497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64070247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64070247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64070247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64070247772
state:  2
rewards[state]:  0.0
state_value:  4.49522497525
state_values[state] = rewards[state] + state_value =  4.49522497525

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49522497525
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49522497525
state:  4
rewards[state]:  0.5
state_value:  4.49522497525
state_values[state] = rewards[state] + state_value =  4.99522497525

iteration: 67 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64070247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64070247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64070247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64070247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64070247772
state_values[state] = rewards[state] + state_value =  3.64070247772

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04570247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04570247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04570247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27663222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27663222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27663222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27663222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27663222995
state:  1
rewards[state]:  0.0
state_value:  4.04570247772
state_values[state] = rewards[state] + state_value =  4.04570247772

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49570247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64113222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64113222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64113222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64113222995
state:  2
rewards[state]:  0.0
state_value:  4.49570247772
state_values[state] = rewards[state] + state_value =  4.49570247772

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49570247772
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49570247772
state:  4
rewards[state]:  0.5
state_value:  4.49570247772
state_values[state] = rewards[state] + state_value =  4.99570247772

iteration: 68 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64113222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64113222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64113222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64113222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64113222995
state_values[state] = rewards[state] + state_value =  3.64113222995

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04613222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04613222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04613222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27701900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27701900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27701900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27701900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27701900695
state:  1
rewards[state]:  0.0
state_value:  4.04613222995
state_values[state] = rewards[state] + state_value =  4.04613222995

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49613222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64151900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64151900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64151900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64151900695
state:  2
rewards[state]:  0.0
state_value:  4.49613222995
state_values[state] = rewards[state] + state_value =  4.49613222995

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49613222995
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49613222995
state:  4
rewards[state]:  0.5
state_value:  4.49613222995
state_values[state] = rewards[state] + state_value =  4.99613222995

iteration: 69 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64151900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64151900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64151900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64151900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64151900695
state_values[state] = rewards[state] + state_value =  3.64151900695

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04651900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04651900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04651900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27736710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27736710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27736710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27736710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27736710626
state:  1
rewards[state]:  0.0
state_value:  4.04651900695
state_values[state] = rewards[state] + state_value =  4.04651900695

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49651900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64186710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64186710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64186710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64186710626
state:  2
rewards[state]:  0.0
state_value:  4.49651900695
state_values[state] = rewards[state] + state_value =  4.49651900695

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49651900695
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49651900695
state:  4
rewards[state]:  0.5
state_value:  4.49651900695
state_values[state] = rewards[state] + state_value =  4.99651900695

iteration: 70 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64186710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64186710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64186710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64186710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64186710626
state_values[state] = rewards[state] + state_value =  3.64186710626

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04686710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04686710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04686710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27768039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27768039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27768039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27768039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27768039563
state:  1
rewards[state]:  0.0
state_value:  4.04686710626
state_values[state] = rewards[state] + state_value =  4.04686710626

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49686710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64218039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64218039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64218039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64218039563
state:  2
rewards[state]:  0.0
state_value:  4.49686710626
state_values[state] = rewards[state] + state_value =  4.49686710626

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49686710626
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49686710626
state:  4
rewards[state]:  0.5
state_value:  4.49686710626
state_values[state] = rewards[state] + state_value =  4.99686710626

iteration: 71 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64218039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64218039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64218039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64218039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64218039563
state_values[state] = rewards[state] + state_value =  3.64218039563

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04718039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04718039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04718039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27796235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27796235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27796235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27796235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27796235607
state:  1
rewards[state]:  0.0
state_value:  4.04718039563
state_values[state] = rewards[state] + state_value =  4.04718039563

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49718039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64246235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64246235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64246235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64246235607
state:  2
rewards[state]:  0.0
state_value:  4.49718039563
state_values[state] = rewards[state] + state_value =  4.49718039563

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49718039563
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49718039563
state:  4
rewards[state]:  0.5
state_value:  4.49718039563
state_values[state] = rewards[state] + state_value =  4.99718039563

iteration: 72 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64246235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64246235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64246235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64246235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64246235607
state_values[state] = rewards[state] + state_value =  3.64246235607

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04746235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04746235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04746235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27821612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27821612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27821612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27821612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27821612046
state:  1
rewards[state]:  0.0
state_value:  4.04746235607
state_values[state] = rewards[state] + state_value =  4.04746235607

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49746235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64271612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64271612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64271612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64271612046
state:  2
rewards[state]:  0.0
state_value:  4.49746235607
state_values[state] = rewards[state] + state_value =  4.49746235607

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49746235607
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49746235607
state:  4
rewards[state]:  0.5
state_value:  4.49746235607
state_values[state] = rewards[state] + state_value =  4.99746235607

iteration: 73 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64271612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64271612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64271612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64271612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64271612046
state_values[state] = rewards[state] + state_value =  3.64271612046

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04771612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04771612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04771612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27844450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27844450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27844450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27844450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27844450842
state:  1
rewards[state]:  0.0
state_value:  4.04771612046
state_values[state] = rewards[state] + state_value =  4.04771612046

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49771612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64294450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64294450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64294450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64294450842
state:  2
rewards[state]:  0.0
state_value:  4.49771612046
state_values[state] = rewards[state] + state_value =  4.49771612046

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49771612046
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49771612046
state:  4
rewards[state]:  0.5
state_value:  4.49771612046
state_values[state] = rewards[state] + state_value =  4.99771612046

iteration: 74 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64294450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64294450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64294450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64294450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64294450842
state_values[state] = rewards[state] + state_value =  3.64294450842

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04794450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04794450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04794450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27865005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27865005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27865005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27865005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27865005757
state:  1
rewards[state]:  0.0
state_value:  4.04794450842
state_values[state] = rewards[state] + state_value =  4.04794450842

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49794450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64315005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64315005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64315005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64315005757
state:  2
rewards[state]:  0.0
state_value:  4.49794450842
state_values[state] = rewards[state] + state_value =  4.49794450842

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49794450842
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49794450842
state:  4
rewards[state]:  0.5
state_value:  4.49794450842
state_values[state] = rewards[state] + state_value =  4.99794450842

iteration: 75 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64315005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64315005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64315005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64315005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64315005757
state_values[state] = rewards[state] + state_value =  3.64315005757

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04815005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04815005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04815005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27883505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27883505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27883505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27883505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27883505182
state:  1
rewards[state]:  0.0
state_value:  4.04815005757
state_values[state] = rewards[state] + state_value =  4.04815005757

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49815005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64333505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64333505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64333505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64333505182
state:  2
rewards[state]:  0.0
state_value:  4.49815005757
state_values[state] = rewards[state] + state_value =  4.49815005757

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49815005757
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49815005757
state:  4
rewards[state]:  0.5
state_value:  4.49815005757
state_values[state] = rewards[state] + state_value =  4.99815005757

iteration: 76 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64333505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64333505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64333505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64333505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64333505182
state_values[state] = rewards[state] + state_value =  3.64333505182

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04833505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04833505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04833505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27900154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27900154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27900154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27900154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27900154664
state:  1
rewards[state]:  0.0
state_value:  4.04833505182
state_values[state] = rewards[state] + state_value =  4.04833505182

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49833505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64350154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64350154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64350154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64350154664
state:  2
rewards[state]:  0.0
state_value:  4.49833505182
state_values[state] = rewards[state] + state_value =  4.49833505182

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49833505182
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49833505182
state:  4
rewards[state]:  0.5
state_value:  4.49833505182
state_values[state] = rewards[state] + state_value =  4.99833505182

iteration: 77 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64350154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64350154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64350154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64350154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64350154664
state_values[state] = rewards[state] + state_value =  3.64350154664

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04850154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04850154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04850154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27915139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27915139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27915139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27915139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27915139197
state:  1
rewards[state]:  0.0
state_value:  4.04850154664
state_values[state] = rewards[state] + state_value =  4.04850154664

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49850154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64365139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64365139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64365139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64365139197
state:  2
rewards[state]:  0.0
state_value:  4.49850154664
state_values[state] = rewards[state] + state_value =  4.49850154664

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49850154664
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49850154664
state:  4
rewards[state]:  0.5
state_value:  4.49850154664
state_values[state] = rewards[state] + state_value =  4.99850154664

iteration: 78 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64365139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64365139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64365139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64365139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64365139197
state_values[state] = rewards[state] + state_value =  3.64365139197

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04865139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04865139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04865139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27928625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27928625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27928625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27928625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27928625277
state:  1
rewards[state]:  0.0
state_value:  4.04865139197
state_values[state] = rewards[state] + state_value =  4.04865139197

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49865139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64378625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64378625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64378625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64378625277
state:  2
rewards[state]:  0.0
state_value:  4.49865139197
state_values[state] = rewards[state] + state_value =  4.49865139197

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49865139197
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49865139197
state:  4
rewards[state]:  0.5
state_value:  4.49865139197
state_values[state] = rewards[state] + state_value =  4.99865139197

iteration: 79 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64378625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64378625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64378625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64378625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64378625277
state_values[state] = rewards[state] + state_value =  3.64378625277

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04878625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04878625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04878625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2794076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2794076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2794076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2794076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2794076275
state:  1
rewards[state]:  0.0
state_value:  4.04878625277
state_values[state] = rewards[state] + state_value =  4.04878625277

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49878625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6439076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6439076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6439076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6439076275
state:  2
rewards[state]:  0.0
state_value:  4.49878625277
state_values[state] = rewards[state] + state_value =  4.49878625277

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49878625277
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49878625277
state:  4
rewards[state]:  0.5
state_value:  4.49878625277
state_values[state] = rewards[state] + state_value =  4.99878625277

iteration: 80 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6439076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6439076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6439076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6439076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.6439076275
state_values[state] = rewards[state] + state_value =  3.6439076275

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0489076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0489076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0489076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27951686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27951686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27951686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27951686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27951686475
state:  1
rewards[state]:  0.0
state_value:  4.0489076275
state_values[state] = rewards[state] + state_value =  4.0489076275

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4989076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64401686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64401686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64401686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64401686475
state:  2
rewards[state]:  0.0
state_value:  4.4989076275
state_values[state] = rewards[state] + state_value =  4.4989076275

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4989076275
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4989076275
state:  4
rewards[state]:  0.5
state_value:  4.4989076275
state_values[state] = rewards[state] + state_value =  4.9989076275

iteration: 81 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64401686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64401686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64401686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64401686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64401686475
state_values[state] = rewards[state] + state_value =  3.64401686475

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04901686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04901686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04901686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27961517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27961517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27961517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27961517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27961517827
state:  1
rewards[state]:  0.0
state_value:  4.04901686475
state_values[state] = rewards[state] + state_value =  4.04901686475

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49901686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64411517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64411517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64411517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64411517827
state:  2
rewards[state]:  0.0
state_value:  4.49901686475
state_values[state] = rewards[state] + state_value =  4.49901686475

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49901686475
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49901686475
state:  4
rewards[state]:  0.5
state_value:  4.49901686475
state_values[state] = rewards[state] + state_value =  4.99901686475

iteration: 82 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64411517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64411517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64411517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64411517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64411517827
state_values[state] = rewards[state] + state_value =  3.64411517827

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04911517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04911517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04911517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27970366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27970366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27970366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27970366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27970366045
state:  1
rewards[state]:  0.0
state_value:  4.04911517827
state_values[state] = rewards[state] + state_value =  4.04911517827

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49911517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64420366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64420366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64420366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64420366045
state:  2
rewards[state]:  0.0
state_value:  4.49911517827
state_values[state] = rewards[state] + state_value =  4.49911517827

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49911517827
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49911517827
state:  4
rewards[state]:  0.5
state_value:  4.49911517827
state_values[state] = rewards[state] + state_value =  4.99911517827

iteration: 83 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64420366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64420366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64420366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64420366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64420366045
state_values[state] = rewards[state] + state_value =  3.64420366045

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04920366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04920366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04920366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2797832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2797832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2797832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2797832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2797832944
state:  1
rewards[state]:  0.0
state_value:  4.04920366045
state_values[state] = rewards[state] + state_value =  4.04920366045

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49920366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6442832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6442832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6442832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6442832944
state:  2
rewards[state]:  0.0
state_value:  4.49920366045
state_values[state] = rewards[state] + state_value =  4.49920366045

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49920366045
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49920366045
state:  4
rewards[state]:  0.5
state_value:  4.49920366045
state_values[state] = rewards[state] + state_value =  4.99920366045

iteration: 84 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6442832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6442832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6442832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6442832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.6442832944
state_values[state] = rewards[state] + state_value =  3.6442832944

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0492832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0492832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0492832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27985496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27985496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27985496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27985496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27985496496
state:  1
rewards[state]:  0.0
state_value:  4.0492832944
state_values[state] = rewards[state] + state_value =  4.0492832944

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4992832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64435496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64435496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64435496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64435496496
state:  2
rewards[state]:  0.0
state_value:  4.4992832944
state_values[state] = rewards[state] + state_value =  4.4992832944

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4992832944
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4992832944
state:  4
rewards[state]:  0.5
state_value:  4.4992832944
state_values[state] = rewards[state] + state_value =  4.9992832944

iteration: 85 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64435496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64435496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64435496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64435496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64435496496
state_values[state] = rewards[state] + state_value =  3.64435496496

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04935496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04935496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04935496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27991946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27991946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27991946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27991946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27991946846
state:  1
rewards[state]:  0.0
state_value:  4.04935496496
state_values[state] = rewards[state] + state_value =  4.04935496496

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49935496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64441946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64441946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64441946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64441946846
state:  2
rewards[state]:  0.0
state_value:  4.49935496496
state_values[state] = rewards[state] + state_value =  4.49935496496

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49935496496
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49935496496
state:  4
rewards[state]:  0.5
state_value:  4.49935496496
state_values[state] = rewards[state] + state_value =  4.99935496496

iteration: 86 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64441946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64441946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64441946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64441946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64441946846
state_values[state] = rewards[state] + state_value =  3.64441946846

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04941946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04941946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04941946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27997752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27997752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27997752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27997752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.27997752162
state:  1
rewards[state]:  0.0
state_value:  4.04941946846
state_values[state] = rewards[state] + state_value =  4.04941946846

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49941946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64447752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64447752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64447752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64447752162
state:  2
rewards[state]:  0.0
state_value:  4.49941946846
state_values[state] = rewards[state] + state_value =  4.49941946846

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49941946846
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49941946846
state:  4
rewards[state]:  0.5
state_value:  4.49941946846
state_values[state] = rewards[state] + state_value =  4.99941946846

iteration: 87 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64447752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64447752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64447752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64447752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64447752162
state_values[state] = rewards[state] + state_value =  3.64447752162

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04947752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04947752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04947752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28002976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28002976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28002976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28002976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28002976946
state:  1
rewards[state]:  0.0
state_value:  4.04947752162
state_values[state] = rewards[state] + state_value =  4.04947752162

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49947752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64452976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64452976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64452976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64452976946
state:  2
rewards[state]:  0.0
state_value:  4.49947752162
state_values[state] = rewards[state] + state_value =  4.49947752162

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49947752162
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49947752162
state:  4
rewards[state]:  0.5
state_value:  4.49947752162
state_values[state] = rewards[state] + state_value =  4.99947752162

iteration: 88 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64452976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64452976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64452976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64452976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64452976946
state_values[state] = rewards[state] + state_value =  3.64452976946

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04952976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04952976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04952976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28007679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28007679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28007679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28007679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28007679251
state:  1
rewards[state]:  0.0
state_value:  4.04952976946
state_values[state] = rewards[state] + state_value =  4.04952976946

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49952976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64457679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64457679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64457679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64457679251
state:  2
rewards[state]:  0.0
state_value:  4.49952976946
state_values[state] = rewards[state] + state_value =  4.49952976946

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49952976946
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49952976946
state:  4
rewards[state]:  0.5
state_value:  4.49952976946
state_values[state] = rewards[state] + state_value =  4.99952976946

iteration: 89 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64457679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64457679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64457679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64457679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64457679251
state_values[state] = rewards[state] + state_value =  3.64457679251

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04957679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04957679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04957679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28011911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28011911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28011911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28011911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28011911326
state:  1
rewards[state]:  0.0
state_value:  4.04957679251
state_values[state] = rewards[state] + state_value =  4.04957679251

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49957679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64461911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64461911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64461911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64461911326
state:  2
rewards[state]:  0.0
state_value:  4.49957679251
state_values[state] = rewards[state] + state_value =  4.49957679251

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49957679251
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49957679251
state:  4
rewards[state]:  0.5
state_value:  4.49957679251
state_values[state] = rewards[state] + state_value =  4.99957679251

iteration: 90 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64461911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64461911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64461911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64461911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64461911326
state_values[state] = rewards[state] + state_value =  3.64461911326

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04961911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04961911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04961911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28015720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28015720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28015720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28015720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28015720193
state:  1
rewards[state]:  0.0
state_value:  4.04961911326
state_values[state] = rewards[state] + state_value =  4.04961911326

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49961911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64465720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64465720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64465720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64465720193
state:  2
rewards[state]:  0.0
state_value:  4.49961911326
state_values[state] = rewards[state] + state_value =  4.49961911326

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49961911326
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49961911326
state:  4
rewards[state]:  0.5
state_value:  4.49961911326
state_values[state] = rewards[state] + state_value =  4.99961911326

iteration: 91 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64465720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64465720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64465720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64465720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64465720193
state_values[state] = rewards[state] + state_value =  3.64465720193

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04965720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04965720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04965720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28019148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28019148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28019148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28019148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28019148174
state:  1
rewards[state]:  0.0
state_value:  4.04965720193
state_values[state] = rewards[state] + state_value =  4.04965720193

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49965720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64469148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64469148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64469148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64469148174
state:  2
rewards[state]:  0.0
state_value:  4.49965720193
state_values[state] = rewards[state] + state_value =  4.49965720193

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49965720193
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49965720193
state:  4
rewards[state]:  0.5
state_value:  4.49965720193
state_values[state] = rewards[state] + state_value =  4.99965720193

iteration: 92 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64469148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64469148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64469148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64469148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64469148174
state_values[state] = rewards[state] + state_value =  3.64469148174

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04969148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04969148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04969148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28022233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28022233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28022233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28022233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28022233357
state:  1
rewards[state]:  0.0
state_value:  4.04969148174
state_values[state] = rewards[state] + state_value =  4.04969148174

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49969148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64472233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64472233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64472233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64472233357
state:  2
rewards[state]:  0.0
state_value:  4.49969148174
state_values[state] = rewards[state] + state_value =  4.49969148174

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49969148174
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49969148174
state:  4
rewards[state]:  0.5
state_value:  4.49969148174
state_values[state] = rewards[state] + state_value =  4.99969148174

iteration: 93 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64472233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64472233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64472233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64472233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64472233357
state_values[state] = rewards[state] + state_value =  3.64472233357

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04972233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04972233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04972233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28025010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28025010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28025010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28025010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28025010021
state:  1
rewards[state]:  0.0
state_value:  4.04972233357
state_values[state] = rewards[state] + state_value =  4.04972233357

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49972233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64475010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64475010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64475010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64475010021
state:  2
rewards[state]:  0.0
state_value:  4.49972233357
state_values[state] = rewards[state] + state_value =  4.49972233357

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49972233357
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49972233357
state:  4
rewards[state]:  0.5
state_value:  4.49972233357
state_values[state] = rewards[state] + state_value =  4.99972233357

iteration: 94 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64475010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64475010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64475010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64475010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64475010021
state_values[state] = rewards[state] + state_value =  3.64475010021

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04975010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04975010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04975010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28027509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28027509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28027509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28027509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28027509019
state:  1
rewards[state]:  0.0
state_value:  4.04975010021
state_values[state] = rewards[state] + state_value =  4.04975010021

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49975010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64477509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64477509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64477509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64477509019
state:  2
rewards[state]:  0.0
state_value:  4.49975010021
state_values[state] = rewards[state] + state_value =  4.49975010021

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49975010021
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49975010021
state:  4
rewards[state]:  0.5
state_value:  4.49975010021
state_values[state] = rewards[state] + state_value =  4.99975010021

iteration: 95 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64477509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64477509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64477509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64477509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64477509019
state_values[state] = rewards[state] + state_value =  3.64477509019

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04977509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04977509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04977509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28029758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28029758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28029758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28029758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28029758117
state:  1
rewards[state]:  0.0
state_value:  4.04977509019
state_values[state] = rewards[state] + state_value =  4.04977509019

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49977509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64479758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64479758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64479758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64479758117
state:  2
rewards[state]:  0.0
state_value:  4.49977509019
state_values[state] = rewards[state] + state_value =  4.49977509019

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49977509019
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49977509019
state:  4
rewards[state]:  0.5
state_value:  4.49977509019
state_values[state] = rewards[state] + state_value =  4.99977509019

iteration: 96 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64479758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64479758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64479758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64479758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64479758117
state_values[state] = rewards[state] + state_value =  3.64479758117

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04979758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04979758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04979758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28031782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28031782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28031782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28031782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28031782305
state:  1
rewards[state]:  0.0
state_value:  4.04979758117
state_values[state] = rewards[state] + state_value =  4.04979758117

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49979758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64481782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64481782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64481782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64481782305
state:  2
rewards[state]:  0.0
state_value:  4.49979758117
state_values[state] = rewards[state] + state_value =  4.49979758117

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49979758117
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49979758117
state:  4
rewards[state]:  0.5
state_value:  4.49979758117
state_values[state] = rewards[state] + state_value =  4.99979758117

iteration: 97 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64481782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64481782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64481782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64481782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64481782305
state_values[state] = rewards[state] + state_value =  3.64481782305

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04981782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04981782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04981782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28033604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28033604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28033604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28033604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28033604075
state:  1
rewards[state]:  0.0
state_value:  4.04981782305
state_values[state] = rewards[state] + state_value =  4.04981782305

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49981782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64483604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64483604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64483604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64483604075
state:  2
rewards[state]:  0.0
state_value:  4.49981782305
state_values[state] = rewards[state] + state_value =  4.49981782305

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49981782305
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49981782305
state:  4
rewards[state]:  0.5
state_value:  4.49981782305
state_values[state] = rewards[state] + state_value =  4.99981782305

iteration: 98 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64483604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64483604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64483604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64483604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64483604075
state_values[state] = rewards[state] + state_value =  3.64483604075

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04983604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04983604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04983604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28035243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28035243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28035243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28035243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28035243667
state:  1
rewards[state]:  0.0
state_value:  4.04983604075
state_values[state] = rewards[state] + state_value =  4.04983604075

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49983604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64485243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64485243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64485243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64485243667
state:  2
rewards[state]:  0.0
state_value:  4.49983604075
state_values[state] = rewards[state] + state_value =  4.49983604075

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49983604075
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49983604075
state:  4
rewards[state]:  0.5
state_value:  4.49983604075
state_values[state] = rewards[state] + state_value =  4.99983604075

iteration: 99 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64485243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64485243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64485243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64485243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64485243667
state_values[state] = rewards[state] + state_value =  3.64485243667

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04985243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04985243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04985243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28036719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28036719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28036719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28036719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28036719301
state:  1
rewards[state]:  0.0
state_value:  4.04985243667
state_values[state] = rewards[state] + state_value =  4.04985243667

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49985243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64486719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64486719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64486719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64486719301
state:  2
rewards[state]:  0.0
state_value:  4.49985243667
state_values[state] = rewards[state] + state_value =  4.49985243667

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49985243667
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49985243667
state:  4
rewards[state]:  0.5
state_value:  4.49985243667
state_values[state] = rewards[state] + state_value =  4.99985243667

iteration: 100 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64486719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64486719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64486719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64486719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64486719301
state_values[state] = rewards[state] + state_value =  3.64486719301

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04986719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04986719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04986719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28038047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28038047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28038047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28038047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28038047371
state:  1
rewards[state]:  0.0
state_value:  4.04986719301
state_values[state] = rewards[state] + state_value =  4.04986719301

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49986719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64488047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64488047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64488047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64488047371
state:  2
rewards[state]:  0.0
state_value:  4.49986719301
state_values[state] = rewards[state] + state_value =  4.49986719301

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49986719301
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49986719301
state:  4
rewards[state]:  0.5
state_value:  4.49986719301
state_values[state] = rewards[state] + state_value =  4.99986719301

iteration: 101 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64488047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64488047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64488047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64488047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64488047371
state_values[state] = rewards[state] + state_value =  3.64488047371

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04988047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04988047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04988047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28039242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28039242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28039242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28039242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28039242633
state:  1
rewards[state]:  0.0
state_value:  4.04988047371
state_values[state] = rewards[state] + state_value =  4.04988047371

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49988047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64489242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64489242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64489242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64489242633
state:  2
rewards[state]:  0.0
state_value:  4.49988047371
state_values[state] = rewards[state] + state_value =  4.49988047371

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49988047371
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49988047371
state:  4
rewards[state]:  0.5
state_value:  4.49988047371
state_values[state] = rewards[state] + state_value =  4.99988047371

iteration: 102 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64489242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64489242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64489242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64489242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64489242633
state_values[state] = rewards[state] + state_value =  3.64489242633

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04989242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04989242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04989242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804031837
state:  1
rewards[state]:  0.0
state_value:  4.04989242633
state_values[state] = rewards[state] + state_value =  4.04989242633

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49989242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449031837
state:  2
rewards[state]:  0.0
state_value:  4.49989242633
state_values[state] = rewards[state] + state_value =  4.49989242633

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49989242633
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49989242633
state:  4
rewards[state]:  0.5
state_value:  4.49989242633
state_values[state] = rewards[state] + state_value =  4.99989242633

iteration: 103 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.6449031837
state_values[state] = rewards[state] + state_value =  3.6449031837

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0499031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0499031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0499031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28041286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28041286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28041286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28041286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28041286533
state:  1
rewards[state]:  0.0
state_value:  4.0499031837
state_values[state] = rewards[state] + state_value =  4.0499031837

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4999031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64491286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64491286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64491286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64491286533
state:  2
rewards[state]:  0.0
state_value:  4.4999031837
state_values[state] = rewards[state] + state_value =  4.4999031837

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4999031837
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4999031837
state:  4
rewards[state]:  0.5
state_value:  4.4999031837
state_values[state] = rewards[state] + state_value =  4.9999031837

iteration: 104 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64491286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64491286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64491286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64491286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64491286533
state_values[state] = rewards[state] + state_value =  3.64491286533

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04991286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04991286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04991286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804215788
state:  1
rewards[state]:  0.0
state_value:  4.04991286533
state_values[state] = rewards[state] + state_value =  4.04991286533

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49991286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449215788
state:  2
rewards[state]:  0.0
state_value:  4.49991286533
state_values[state] = rewards[state] + state_value =  4.49991286533

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49991286533
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49991286533
state:  4
rewards[state]:  0.5
state_value:  4.49991286533
state_values[state] = rewards[state] + state_value =  4.99991286533

iteration: 105 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.6449215788
state_values[state] = rewards[state] + state_value =  3.6449215788

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0499215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0499215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0499215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28042942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28042942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28042942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28042942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28042942092
state:  1
rewards[state]:  0.0
state_value:  4.0499215788
state_values[state] = rewards[state] + state_value =  4.0499215788

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4999215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64492942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64492942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64492942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64492942092
state:  2
rewards[state]:  0.0
state_value:  4.4999215788
state_values[state] = rewards[state] + state_value =  4.4999215788

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4999215788
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4999215788
state:  4
rewards[state]:  0.5
state_value:  4.4999215788
state_values[state] = rewards[state] + state_value =  4.9999215788

iteration: 106 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64492942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64492942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64492942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64492942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64492942092
state_values[state] = rewards[state] + state_value =  3.64492942092

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04992942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04992942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04992942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28043647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28043647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28043647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28043647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28043647883
state:  1
rewards[state]:  0.0
state_value:  4.04992942092
state_values[state] = rewards[state] + state_value =  4.04992942092

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49992942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64493647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64493647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64493647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64493647883
state:  2
rewards[state]:  0.0
state_value:  4.49992942092
state_values[state] = rewards[state] + state_value =  4.49992942092

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49992942092
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49992942092
state:  4
rewards[state]:  0.5
state_value:  4.49992942092
state_values[state] = rewards[state] + state_value =  4.99992942092

iteration: 107 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64493647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64493647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64493647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64493647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64493647883
state_values[state] = rewards[state] + state_value =  3.64493647883

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04993647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04993647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04993647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28044283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28044283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28044283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28044283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28044283094
state:  1
rewards[state]:  0.0
state_value:  4.04993647883
state_values[state] = rewards[state] + state_value =  4.04993647883

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49993647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494283094
state:  2
rewards[state]:  0.0
state_value:  4.49993647883
state_values[state] = rewards[state] + state_value =  4.49993647883

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49993647883
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49993647883
state:  4
rewards[state]:  0.5
state_value:  4.49993647883
state_values[state] = rewards[state] + state_value =  4.99993647883

iteration: 108 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64494283094
state_values[state] = rewards[state] + state_value =  3.64494283094

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04994283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04994283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04994283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28044854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28044854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28044854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28044854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28044854785
state:  1
rewards[state]:  0.0
state_value:  4.04994283094
state_values[state] = rewards[state] + state_value =  4.04994283094

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49994283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494854785
state:  2
rewards[state]:  0.0
state_value:  4.49994283094
state_values[state] = rewards[state] + state_value =  4.49994283094

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49994283094
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49994283094
state:  4
rewards[state]:  0.5
state_value:  4.49994283094
state_values[state] = rewards[state] + state_value =  4.99994283094

iteration: 109 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64494854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64494854785
state_values[state] = rewards[state] + state_value =  3.64494854785

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04994854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04994854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04994854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28045369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28045369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28045369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28045369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28045369306
state:  1
rewards[state]:  0.0
state_value:  4.04994854785
state_values[state] = rewards[state] + state_value =  4.04994854785

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49994854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495369306
state:  2
rewards[state]:  0.0
state_value:  4.49994854785
state_values[state] = rewards[state] + state_value =  4.49994854785

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49994854785
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49994854785
state:  4
rewards[state]:  0.5
state_value:  4.49994854785
state_values[state] = rewards[state] + state_value =  4.99994854785

iteration: 110 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64495369306
state_values[state] = rewards[state] + state_value =  3.64495369306

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04995369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04995369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04995369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28045832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28045832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28045832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28045832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28045832376
state:  1
rewards[state]:  0.0
state_value:  4.04995369306
state_values[state] = rewards[state] + state_value =  4.04995369306

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49995369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495832376
state:  2
rewards[state]:  0.0
state_value:  4.49995369306
state_values[state] = rewards[state] + state_value =  4.49995369306

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49995369306
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49995369306
state:  4
rewards[state]:  0.5
state_value:  4.49995369306
state_values[state] = rewards[state] + state_value =  4.99995369306

iteration: 111 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64495832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64495832376
state_values[state] = rewards[state] + state_value =  3.64495832376

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04995832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04995832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04995832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046249138
state:  1
rewards[state]:  0.0
state_value:  4.04995832376
state_values[state] = rewards[state] + state_value =  4.04995832376

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49995832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496249138
state:  2
rewards[state]:  0.0
state_value:  4.49995832376
state_values[state] = rewards[state] + state_value =  4.49995832376

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49995832376
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49995832376
state:  4
rewards[state]:  0.5
state_value:  4.49995832376
state_values[state] = rewards[state] + state_value =  4.99995832376

iteration: 112 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64496249138
state_values[state] = rewards[state] + state_value =  3.64496249138

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04996249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04996249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04996249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046624224
state:  1
rewards[state]:  0.0
state_value:  4.04996249138
state_values[state] = rewards[state] + state_value =  4.04996249138

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49996249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496624224
state:  2
rewards[state]:  0.0
state_value:  4.49996249138
state_values[state] = rewards[state] + state_value =  4.49996249138

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49996249138
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49996249138
state:  4
rewards[state]:  0.5
state_value:  4.49996249138
state_values[state] = rewards[state] + state_value =  4.99996249138

iteration: 113 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64496624224
state_values[state] = rewards[state] + state_value =  3.64496624224

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04996624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04996624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04996624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28046961802
state:  1
rewards[state]:  0.0
state_value:  4.04996624224
state_values[state] = rewards[state] + state_value =  4.04996624224

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49996624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496961802
state:  2
rewards[state]:  0.0
state_value:  4.49996624224
state_values[state] = rewards[state] + state_value =  4.49996624224

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49996624224
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49996624224
state:  4
rewards[state]:  0.5
state_value:  4.49996624224
state_values[state] = rewards[state] + state_value =  4.99996624224

iteration: 114 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64496961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64496961802
state_values[state] = rewards[state] + state_value =  3.64496961802

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04996961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04996961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04996961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28047265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28047265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28047265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28047265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28047265622
state:  1
rewards[state]:  0.0
state_value:  4.04996961802
state_values[state] = rewards[state] + state_value =  4.04996961802

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49996961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497265622
state:  2
rewards[state]:  0.0
state_value:  4.49996961802
state_values[state] = rewards[state] + state_value =  4.49996961802

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49996961802
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49996961802
state:  4
rewards[state]:  0.5
state_value:  4.49996961802
state_values[state] = rewards[state] + state_value =  4.99996961802

iteration: 115 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64497265622
state_values[state] = rewards[state] + state_value =  3.64497265622

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04997265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04997265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04997265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804753906
state:  1
rewards[state]:  0.0
state_value:  4.04997265622
state_values[state] = rewards[state] + state_value =  4.04997265622

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49997265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449753906
state:  2
rewards[state]:  0.0
state_value:  4.49997265622
state_values[state] = rewards[state] + state_value =  4.49997265622

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49997265622
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49997265622
state:  4
rewards[state]:  0.5
state_value:  4.49997265622
state_values[state] = rewards[state] + state_value =  4.99997265622

iteration: 116 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.6449753906
state_values[state] = rewards[state] + state_value =  3.6449753906

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0499753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0499753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0499753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28047785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28047785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28047785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28047785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28047785154
state:  1
rewards[state]:  0.0
state_value:  4.0499753906
state_values[state] = rewards[state] + state_value =  4.0499753906

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4999753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497785154
state:  2
rewards[state]:  0.0
state_value:  4.4999753906
state_values[state] = rewards[state] + state_value =  4.4999753906

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4999753906
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4999753906
state:  4
rewards[state]:  0.5
state_value:  4.4999753906
state_values[state] = rewards[state] + state_value =  4.9999753906

iteration: 117 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64497785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64497785154
state_values[state] = rewards[state] + state_value =  3.64497785154

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04997785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04997785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04997785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048006638
state:  1
rewards[state]:  0.0
state_value:  4.04997785154
state_values[state] = rewards[state] + state_value =  4.04997785154

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49997785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498006638
state:  2
rewards[state]:  0.0
state_value:  4.49997785154
state_values[state] = rewards[state] + state_value =  4.49997785154

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49997785154
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49997785154
state:  4
rewards[state]:  0.5
state_value:  4.49997785154
state_values[state] = rewards[state] + state_value =  4.99997785154

iteration: 118 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64498006638
state_values[state] = rewards[state] + state_value =  3.64498006638

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048205974
state:  1
rewards[state]:  0.0
state_value:  4.04998006638
state_values[state] = rewards[state] + state_value =  4.04998006638

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498205974
state:  2
rewards[state]:  0.0
state_value:  4.49998006638
state_values[state] = rewards[state] + state_value =  4.49998006638

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998006638
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998006638
state:  4
rewards[state]:  0.5
state_value:  4.49998006638
state_values[state] = rewards[state] + state_value =  4.99998006638

iteration: 119 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64498205974
state_values[state] = rewards[state] + state_value =  3.64498205974

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048385377
state:  1
rewards[state]:  0.0
state_value:  4.04998205974
state_values[state] = rewards[state] + state_value =  4.04998205974

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498385377
state:  2
rewards[state]:  0.0
state_value:  4.49998205974
state_values[state] = rewards[state] + state_value =  4.49998205974

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998205974
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998205974
state:  4
rewards[state]:  0.5
state_value:  4.49998205974
state_values[state] = rewards[state] + state_value =  4.99998205974

iteration: 120 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64498385377
state_values[state] = rewards[state] + state_value =  3.64498385377

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048546839
state:  1
rewards[state]:  0.0
state_value:  4.04998385377
state_values[state] = rewards[state] + state_value =  4.04998385377

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498546839
state:  2
rewards[state]:  0.0
state_value:  4.49998385377
state_values[state] = rewards[state] + state_value =  4.49998385377

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998385377
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998385377
state:  4
rewards[state]:  0.5
state_value:  4.49998385377
state_values[state] = rewards[state] + state_value =  4.99998385377

iteration: 121 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64498546839
state_values[state] = rewards[state] + state_value =  3.64498546839

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048692155
state:  1
rewards[state]:  0.0
state_value:  4.04998546839
state_values[state] = rewards[state] + state_value =  4.04998546839

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498692155
state:  2
rewards[state]:  0.0
state_value:  4.49998546839
state_values[state] = rewards[state] + state_value =  4.49998546839

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998546839
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998546839
state:  4
rewards[state]:  0.5
state_value:  4.49998546839
state_values[state] = rewards[state] + state_value =  4.99998546839

iteration: 122 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64498692155
state_values[state] = rewards[state] + state_value =  3.64498692155

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.2804882294
state:  1
rewards[state]:  0.0
state_value:  4.04998692155
state_values[state] = rewards[state] + state_value =  4.04998692155

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449882294
state:  2
rewards[state]:  0.0
state_value:  4.49998692155
state_values[state] = rewards[state] + state_value =  4.49998692155

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998692155
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998692155
state:  4
rewards[state]:  0.5
state_value:  4.49998692155
state_values[state] = rewards[state] + state_value =  4.99998692155

iteration: 123 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.6449882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.6449882294
state_values[state] = rewards[state] + state_value =  3.6449882294

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0499882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0499882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.0499882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28048940646
state:  1
rewards[state]:  0.0
state_value:  4.0499882294
state_values[state] = rewards[state] + state_value =  4.0499882294

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4999882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498940646
state:  2
rewards[state]:  0.0
state_value:  4.4999882294
state_values[state] = rewards[state] + state_value =  4.4999882294

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4999882294
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.4999882294
state:  4
rewards[state]:  0.5
state_value:  4.4999882294
state_values[state] = rewards[state] + state_value =  4.9999882294

iteration: 124 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64498940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64498940646
state_values[state] = rewards[state] + state_value =  3.64498940646

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04998940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28049046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28049046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28049046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28049046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28049046581
state:  1
rewards[state]:  0.0
state_value:  4.04998940646
state_values[state] = rewards[state] + state_value =  4.04998940646

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64499046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64499046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64499046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64499046581
state:  2
rewards[state]:  0.0
state_value:  4.49998940646
state_values[state] = rewards[state] + state_value =  4.49998940646

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998940646
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49998940646
state:  4
rewards[state]:  0.5
state_value:  4.49998940646
state_values[state] = rewards[state] + state_value =  4.99998940646

iteration: 125 / 125
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64499046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64499046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64499046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64499046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  0
rewards[state]:  0.0
state_value:  3.64499046581
state_values[state] = rewards[state] + state_value =  3.64499046581

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04999046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04999046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.04999046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28049141923
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28049141923
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28049141923
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28049141923
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.28049141923
state:  1
rewards[state]:  0.0
state_value:  4.04999046581
state_values[state] = rewards[state] + state_value =  4.04999046581

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49999046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64499141923
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64499141923
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64499141923
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  3.64499141923
state:  2
rewards[state]:  0.0
state_value:  4.49999046581
state_values[state] = rewards[state] + state_value =  4.49999046581

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
state:  3
rewards[state]:  0.0
state_value:  0.0
state_values[state] = rewards[state] + state_value =  0.0

action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49999046581
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  0.0
action_value += (P[state][action][state_] * state_values[state_] * GAMMA =  4.49999046581
state:  4
rewards[state]:  0.5
state_value:  4.49999046581
state_values[state] = rewards[state] + state_value =  4.99999046581

best_policy:  [ 0.  0.  0.  1.  1.]
{'high': 'climb', 'top': 'sink', 'bottom': 'sink', 'low': 'climb', 'mid': 'climb'}
